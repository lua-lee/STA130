{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9390d84c",
   "metadata": {},
   "source": [
    "Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv(\"students.csv\")\n",
    "\n",
    "# Display the dataset\n",
    "print(df)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a5286",
   "metadata": {},
   "source": [
    "### Summary of Interactions\n",
    "\n",
    "In our exchanges, we worked on handling missing data in a dataset using Python and the pandas library. Here's a step-by-step breakdown of the tasks and code we worked on:\n",
    "\n",
    "1. **Creating a Dataset with Missing Values:**\n",
    "   - I provided a simple CSV dataset called `students.csv`, which included missing values in some columns. The dataset looked like this:\n",
    "   \n",
    "   ```csv\n",
    "   Name,Age,Grade,Gender\n",
    "   John,17,90,M\n",
    "   Sarah,16,,F\n",
    "   Jake,18,85,M\n",
    "   ,19,88,F\n",
    "   Laura,17,92,\n",
    "   Paul,18,90,M\n",
    "   ```\n",
    "\n",
    "2. **Combining Dataset with Code to Confirm Missing Values:**\n",
    "   - You requested to combine the CSV file into the code that confirms missing values. Here’s the code we used:\n",
    "   \n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   from io import StringIO\n",
    "\n",
    "   # Creating the CSV data as a string\n",
    "   data = \"\"\"Name,Age,Grade,Gender\n",
    "   John,17,90,M\n",
    "   Sarah,16,,F\n",
    "   Jake,18,85,M\n",
    "   ,19,88,F\n",
    "   Laura,17,92,\n",
    "   Paul,18,90,M\n",
    "   \"\"\"\n",
    "\n",
    "   # Use StringIO to simulate reading from a CSV file\n",
    "   df = pd.read_csv(StringIO(data))\n",
    "\n",
    "   # Display the dataset\n",
    "   print(df)\n",
    "\n",
    "   # Check for missing values\n",
    "   print(\"\\nMissing values in the dataset:\\n\")\n",
    "   print(df.isnull().sum())\n",
    "   ```\n",
    "\n",
    "3. **Output of the Dataset and Missing Values Check:**\n",
    "   - After running the above code, the following dataset and summary of missing values were displayed:\n",
    "\n",
    "   Dataset:\n",
    "\n",
    "   ```\n",
    "       Name   Age  Grade  Gender\n",
    "   0   John    17   90.0       M\n",
    "   1  Sarah    16    NaN       F\n",
    "   2   Jake    18   85.0       M\n",
    "   3    NaN    19   88.0       F\n",
    "   4  Laura    17   92.0     NaN\n",
    "   5   Paul    18   90.0       M\n",
    "   ```\n",
    "\n",
    "   Missing values summary:\n",
    "\n",
    "   - **Name**: 1 missing value\n",
    "   - **Age**: 0 missing values\n",
    "   - **Grade**: 1 missing value\n",
    "   - **Gender**: 1 missing value\n",
    "\n",
    "This interaction involved creating a dataset with missing values, importing it using the `pd.read_csv()` method, and confirming the missing values using the `df.isnull().sum()` function in pandas. The dataset was stored as a string and read using `StringIO` to simulate file handling.\n",
    "\n",
    "link: https://chatgpt.com/c/66e37a54-60e4-800d-95bc-637db6961513 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a06b0",
   "metadata": {},
   "source": [
    "Q2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['Toronto', 'Vancouver', 'Montreal']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(f'Number of rows: {num_rows}')\n",
    "print(f'Number of columns: {num_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23261de",
   "metadata": {},
   "source": [
    "Q2-2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009543d",
   "metadata": {},
   "source": [
    "My own general definitions of the meaning of \"observations\" and \"variables\"\n",
    "\n",
    "Observation = Observation refers to rows which show the individual records.That means each obervsation includes multiple variables. For example, if I have a dataset of UoftT, observation is like a specific course, including details such as the course ID, course name, the professor teaching it, the semester it’s offered, and the department it’s associated with.\n",
    "\n",
    "Variables = Variables refers to columns where you can see the different types of information about each observation. In other words, variables gather to make a full observation. For example, in the UoftT dataset, variables could include course_name, department_name, course_code, and credits. Each variable holds specific data about each observation (row)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e3e8c",
   "metadata": {},
   "source": [
    "### Summary of Exchanges\n",
    "\n",
    "**1. Understanding DataFrame Dimensions**\n",
    "- **Request**: User asked for a code snippet to determine the number of rows and columns in a pandas DataFrame.\n",
    "- **Response**: Provided a Python code example using `df.shape` to get the number of rows and columns.\n",
    "\n",
    "**2. Definitions of Observations and Variables**\n",
    "- **Request**: User sought clarification on the meanings of \"observations\" and \"variables\" in the context of a dataset.\n",
    "- **Response**: Explained that:\n",
    "  - **Observations** are individual rows in a dataset, each representing a single data point or instance.\n",
    "  - **Variables** are columns in a dataset, each representing a different attribute or piece of information about the observations.\n",
    "\n",
    "**3. Examples for Observations and Variables**\n",
    "- **Request**: User provided examples related to a University of Toronto (UoftT) dataset and asked for verification.\n",
    "- **Response**: Confirmed that:\n",
    "  - **Observations**: In the UoftT dataset, an observation represents a specific course with details such as course ID, name, professor, semester, and department.\n",
    "  - **Variables**: In the UoftT dataset, variables include course name, department name, course code, and credits, each holding specific data about the courses.\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e37cb4-d5e0-800d-93de-69210472307b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9966bf",
   "metadata": {},
   "source": [
    "Q3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named df\n",
    "summary = df.describe()\n",
    "print(summary)\n",
    "\n",
    "# For a specific column, e.g., 'course_name'\n",
    "value_counts = df['course_name'].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a12add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'course_id': [101, 102, 103, 104, 105, 106],\n",
    "    'course_name': ['Math', 'English', 'Biology', 'Math', 'Physics', 'English'],\n",
    "    'professor': ['Dr. Smith', 'Dr. Jones', 'Dr. Brown', 'Dr. Smith', 'Dr. Lee', 'Dr. Jones'],\n",
    "    'credits': [3, 4, 3, 3, 4, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get a summary of numeric columns\n",
    "numeric_summary = df.describe()\n",
    "print(\"Summary of numeric columns:\")\n",
    "print(numeric_summary)\n",
    "\n",
    "# Get the frequency of unique values in the 'course_name' column\n",
    "course_name_counts = df['course_name'].value_counts()\n",
    "print(\"\\nFrequency of unique course names:\")\n",
    "print(course_name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3a8b9",
   "metadata": {},
   "source": [
    "Note: \n",
    "df.describe(): This method provides a statistical summary of numeric columns in the DataFrame. It gives you insights into the distribution of the data, including metrics like mean, standard deviation, minimum, and maximum values, as well as the quartiles.\n",
    "\n",
    "df['column'].value_counts(): This method provides a summary of the frequency of unique values in a specific column. It's particularly useful for categorical data to understand the distribution of different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b9c0b",
   "metadata": {},
   "source": [
    "### Summary of Interactions\n",
    "\n",
    "#### Topic: Data Manipulation with Pandas\n",
    "\n",
    "1. **Handling Missing Data:**\n",
    "   - **Methods Discussed:**\n",
    "     - `df.dropna()`: Removes rows with missing values.\n",
    "     - `del df['col']`: Deletes a column from the DataFrame.\n",
    "\n",
    "2. **Using `df.describe()` and `df['column'].value_counts()`:**\n",
    "   - **`df.describe()`:** \n",
    "     - Provides statistical summaries of numeric columns, including metrics like mean, standard deviation, and quartiles.\n",
    "     - Example provided for a DataFrame with 'course_id' and 'credits'.\n",
    "   - **`df['column'].value_counts()`:**\n",
    "     - Shows the frequency of unique values in a categorical column.\n",
    "     - Example provided for the 'course_name' column.\n",
    "\n",
    "3. **Examples:**\n",
    "   - **Numeric Summary with `df.describe()`:**\n",
    "     - Provided a sample DataFrame and used `df.describe()` to summarize 'course_id' and 'credits'.\n",
    "   - **Frequency Count with `df['column'].value_counts()`:**\n",
    "     - Demonstrated how to count occurrences of unique values in the 'course_name' column.\n",
    "\n",
    "#### Personal Insights:\n",
    "\n",
    "- **City Context (Toronto):**\n",
    "  - User feels both energized and pressured by the city’s busyness.\n",
    "  - Experiences a mix of motivation and stress from the city’s environment and social issues.\n",
    "\n",
    "- **Dataset Context:**\n",
    "  - User is working with a dataset related to the University of Toronto, focusing on columns like course ID, course name, professor, semester, department, and credits.\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e38083-dd28-800d-8057-b3eb216b450b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10833fb",
   "metadata": {},
   "source": [
    "Q4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f50f8",
   "metadata": {},
   "source": [
    "size of the dataset given by df.shape vs. what is reported by df.describe()\n",
    "\n",
    "1. Understand the Dataset:\n",
    "Non-numeric variables: These are columns with data that are not numbers, such as text or categorical data (e.g., names, labels).\n",
    "Missing values in numeric variables: These are entries in columns with numbers where some values are missing (NaNs).\n",
    "\n",
    "2. Compare df.shape and df.describe():\n",
    "a) The number of columns analyzed:\n",
    "\n",
    "df.shape: This function returns a tuple (number_of_rows, number_of_columns). It tells you the dimensions of the entire DataFrame but does not give details about the content of the columns.(= We only know the num of rows and columns)\n",
    "\n",
    "df.describe(): This function provides summary statistics of numeric columns by default. It excludes non-numeric columns unless you specify include='all'. By default, df.describe() will only analyze numeric columns, so if you have non-numeric columns in your dataset, they will not be included in the describe() output.\n",
    "\n",
    "b) The values reported in the \"count\" column:\n",
    "\n",
    "df.describe(): The \"count\" in df.describe() refers to the number of non-missing (valid) values in each numeric column. If a numeric column has missing values, the count will be less than the total number of rows in the DataFrame.\n",
    "\n",
    "df.shape: The total number of rows, including those with missing values, is given by df.shape[0]. This includes every row regardless of missing values.\n",
    "\n",
    "3. Summary:\n",
    "df.describe() usually reports fewer columns and counts fewer non-missing values compared to what is shown by df.shape. And this is because df.describe() focuses on numeric columns and excludes rows with missing values in those columns from its count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a00a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of Q4\n",
    "\n",
    "#Assume you have the following DataFrame:\n",
    "\n",
    "ID\tAge\tGrade\tDepartment\n",
    "1\t21\t85\tMath\n",
    "2\tNaN\t90\tScience\n",
    "3\t22\tNaN\tHistory\n",
    "4\t20\t88\tMath\n",
    "\n",
    "#Here’s how df.shape and df.describe() would compare:\n",
    "df.shape: \n",
    "    Output: (4, 4) – This shows there are 4 rows and 4 columns in the DataFrame.\n",
    "        \n",
    "df.describe():\n",
    "    Output:       \n",
    "        Age  Grade\n",
    "count  3.0   3.0\n",
    "mean  21.0  87.67\n",
    "std    1.0   2.52\n",
    "min   20.0  85.0\n",
    "25%   20.5  86.0\n",
    "50%   21.0  88.0\n",
    "75%   21.5  89.0\n",
    "max   22.0  90.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0874d3",
   "metadata": {},
   "source": [
    "### Summary of Exchanges:\n",
    "\n",
    "**Task Breakdown:**\n",
    "\n",
    "1. **Dataset Details**:\n",
    "   - **Non-numeric Variables**: Columns with data that are not numbers (e.g., text or categorical data).\n",
    "   - **Missing Values in Numeric Variables**: Entries in numeric columns where some values are missing (NaNs).\n",
    "\n",
    "2. **Comparison of `df.shape` and `df.describe()`**:\n",
    "   - **`df.shape`**: Returns the dimensions of the DataFrame, showing the total number of rows and columns, including all types of columns and rows with missing values.\n",
    "   - **`df.describe()`**: Provides summary statistics for numeric columns by default. It excludes non-numeric columns and reports the count of non-missing values in each numeric column.\n",
    "\n",
    "   **Discrepancies**:\n",
    "   - **Number of Columns**:\n",
    "     - `df.shape` includes all columns (numeric and non-numeric).\n",
    "     - `df.describe()` includes only numeric columns by default.\n",
    "   - **Count of Values**:\n",
    "     - `df.shape` shows the total number of rows, including those with missing values.\n",
    "     - `df.describe()` shows the count of non-missing values for each numeric column, which may be less than the total number of rows due to missing values.\n",
    "\n",
    "**Example Illustration**:\n",
    "- A DataFrame with columns `ID`, `Age`, `Grade`, and `Department`.\n",
    "- `df.shape` shows dimensions `(4, 4)`, indicating 4 rows and 4 columns.\n",
    "- `df.describe()` shows summary statistics only for numeric columns `Age` and `Grade`, with counts of non-missing values in those columns.\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e382a3-b4b0-800d-9415-a138f9751a99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5a4db",
   "metadata": {},
   "source": [
    "Q5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b111900",
   "metadata": {},
   "source": [
    "Attritbute: Attributes are like characteristics of an object. \n",
    "            You get an attribute by referring to it directly like df.shape, which shows the size of a DataFrame. \n",
    "            Since it access directly, we don't need to use parentheses at the end unlike method (does not require arguments). \n",
    "            You don't need to perform something.\n",
    "\n",
    "Method: Methods are actions an object can perform. \n",
    "        You use methods by calling them with parenthesess since we can't access directly, like df.describe(), which gives you a summary of the DataFrame's data. \n",
    "        You need to perform something \n",
    "\n",
    "Example:\n",
    "Attribute: df.shape returns (3, 3), indicating the DataFrame has 3 rows and 3 columns.\n",
    "Method: df.describe() provides summary statistics for numeric columns such as mean, standard deviation, and quartiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af222f77",
   "metadata": {},
   "source": [
    "### Summary of Interaction on Attributes vs. Methods\n",
    "\n",
    "In our discussion, we covered the key differences between an **attribute** and a **method** in pandas (and Python in general):\n",
    "\n",
    "- **Attributes** (e.g., `df.shape`) are **properties** of an object, which store and provide information directly. They don’t require parentheses `()` because they simply return a value that is already stored within the object.\n",
    "  \n",
    "- **Methods** (e.g., `df.describe()`) are **functions** associated with an object. They require parentheses because they perform actions or calculations. Methods can take arguments to modify their behavior, though some methods don't require any arguments by default.\n",
    "\n",
    "The comparison highlights that attributes passively retrieve data, while methods actively perform operations.\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e38717-bbbc-800d-875b-77507cfc9fa7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a015e6",
   "metadata": {},
   "source": [
    "Q6. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48dc4f",
   "metadata": {},
   "source": [
    "1. **Count**: The number of non-missing (non-NaN) values in the data for each variable.\n",
    "   - Example: In a column with 10 values, if 2 are missing, the count will be 8.\n",
    "\n",
    "2. **Mean**: The average of the data for each variable. It's calculated by summing up all the values and dividing by the count.\n",
    "   - Formula: \\( \\text{Mean} = \\frac{\\sum x_i}{n} \\)\n",
    "   - Example: If you have grades [80, 85, 90], the mean is \\( \\frac{80 + 85 + 90}{3} = 85 \\).\n",
    "\n",
    "3. **Std (Standard Deviation)**: A measure of the amount of variation or dispersion in the data. A higher standard deviation means the values are more spread out from the mean.\n",
    "   - Formula: \\( \\text{Std} = \\sqrt{\\frac{1}{n} \\sum (x_i - \\mu)^2} \\)\n",
    "   - Example: If the grades are [80, 85, 90], the standard deviation shows how much they vary from the average (85).\n",
    "\n",
    "4. **Min (Minimum)**: The smallest value in the dataset for each variable.\n",
    "   - Example: If you have [80, 85, 90], the minimum is 80.\n",
    "\n",
    "5. **25% (1st Quartile)**: The value below which 25% of the data falls. It divides the lowest 25% of the data from the rest.\n",
    "   - Example: For the dataset [80, 85, 90, 95, 100], the 1st quartile is around 85.\n",
    "\n",
    "6. **50% (Median)**: The middle value of the dataset, where 50% of the values are below and 50% are above. It’s the 2nd quartile.\n",
    "   - Example: In [80, 85, 90], the median is 85.\n",
    "\n",
    "7. **75% (3rd Quartile)**: The value below which 75% of the data falls, dividing the lowest 75% of the data from the highest 25%.\n",
    "   - Example: In [80, 85, 90, 95, 100], the 3rd quartile is around 95.\n",
    "\n",
    "8. **Max (Maximum)**: The largest value in the dataset for each variable.\n",
    "   - Example: In [80, 85, 90], the maximum is 90.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b55fc",
   "metadata": {},
   "source": [
    "### Summary of Interaction:\n",
    "\n",
    "You asked for definitions of the summary statistics provided by `df.describe()`, specifically focusing on what each metric represents. Here’s the breakdown:\n",
    "\n",
    "1. **Count**: The number of non-missing (non-NaN) values for each variable.\n",
    "2. **Mean**: The average value of the dataset.\n",
    "3. **Standard Deviation (Std)**: A measure of the spread or dispersion of the data.\n",
    "4. **Min (Minimum)**: The smallest value in the dataset.\n",
    "5. **25% (1st Quartile)**: The value below which 25% of the data points fall.\n",
    "6. **50% (Median)**: The middle value, where half of the data points are below and half are above.\n",
    "7. **75% (3rd Quartile)**: The value below which 75% of the data points fall.\n",
    "8. **Max (Maximum)**: The largest value in the dataset.\n",
    "\n",
    "Afterward, you requested more specificity for the explanations, and I outlined that each statistic gives you insight into the data’s distribution, including examples like a list of grades [80, 85, 90] to explain how these metrics are calculated in practical terms. \n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e38a61-06b0-800d-b025-57300195ba4f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441196ea",
   "metadata": {},
   "source": [
    "Q7. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ae74e",
   "metadata": {},
   "source": [
    "1. Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "We use df.dropna() instead of df['col'] when we want to keep data as much as we can while removing missing values. \n",
    "\n",
    "\n",
    "2. Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "If there are so many missing data in column and we need some space to write the code as much as we can, we use df['col'] to delete the whole thing. \n",
    "\n",
    "3. Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "Doing things with df['col'] before using df.dropna() means that I handle specific column tasks first. This way, I make sure any important operations or fixes related to that column are done before removing rows. This approach helps keep my data accurate, ensures I clean it up properly, and makes sure I don’t accidentally lose important information.\n",
    "\n",
    "\n",
    "4. Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7-4 example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'course_id': [101, 102, 103, 104, 105],\n",
    "    'course_name': ['Math', 'Science', None, 'History', 'Physics'],\n",
    "    'professor': ['Smith', 'Johnson', 'None', None, 'Williams'],\n",
    "    'semester': ['Fall', 'Spring', 'Fall', 'Spring', 'Fall'],\n",
    "    'department': ['Math', 'Science', 'Science', None, None],\n",
    "    'credits': [4, 3, 3, 4, 2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Before cleaning\n",
    "print(\"Before Cleaning:\")\n",
    "print(df)\n",
    "print(\"\\nMissing data in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Justification: \n",
    "# Let's assume the 'department' column has too much missing data and is not critical for analysis,\n",
    "# so we will delete this column. We also want to remove rows where any of the other columns have missing values\n",
    "# because the rest of the data should be complete for analysis.\n",
    "\n",
    "# Remove the 'department' column because it has too many missing values\n",
    "del df['department']\n",
    "\n",
    "# Drop rows with missing data in any remaining columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# After cleaning\n",
    "print(\"\\nAfter Cleaning:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# Reporting\n",
    "print(\"\\nReport of Changes:\")\n",
    "print(f\"Rows before cleaning: {len(data['course_id'])}\")\n",
    "print(f\"Rows after cleaning: {len(df_cleaned)}\")\n",
    "\n",
    "print(f\"\\nColumns before cleaning: {len(data.keys())}\")\n",
    "print(f\"Columns after cleaning: {len(df_cleaned.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9873d12c",
   "metadata": {},
   "source": [
    "note:\n",
    "Missing data can be thought of in two ways: \n",
    "\n",
    "1. **Across rows** – This refers to data that is missing in certain rows, but other parts of the row may contain valid information. For example, in a dataset where student grades are recorded, some rows may be missing values for certain exams, while other exams are recorded for that student. This view focuses on how each row (or entry) is missing some portion of data.\n",
    "\n",
    "2. **Down columns** – This refers to data missing within specific columns. In this view, a particular feature (like a professor’s name for a course) may be missing for some rows, but other columns like course credits or semester might still be complete. This view is focused on how the missing data affects entire variables (or columns) across the dataset.\n",
    "\n",
    "### Efficient Use of `df.dropna()` and `del df['col']`\n",
    "\n",
    "- **`df.dropna()`**: When you use `df.dropna()`, it removes **rows** where **any** or **all** values are missing (depending on the options used). To efficiently manage missing data across rows, you can consider:\n",
    "   - Use `df.dropna(how=\"any\")` if a row with even one missing value is not useful for analysis.\n",
    "   - Use `df.dropna(how=\"all\")` if you only want to remove rows where **every** value is missing, preserving rows with partial data.\n",
    "   - Additionally, you can focus only on certain columns by using `subset=[\"col1\", \"col2\"]` to drop rows based on missing values in specific columns.\n",
    "\n",
    "   This is useful when you want to maintain as much complete data as possible from **rows** while removing those that are too incomplete for meaningful analysis.\n",
    "\n",
    "- **`del df['col']`**: If a **column** has too much missing data, it may be more efficient to delete it entirely. This approach focuses on preserving the other, more complete columns. For example, if a course's department information is missing in most rows, and this information is not critical for the analysis, you can remove the column with `del df['department']`. \n",
    "\n",
    "   This strategy works well when you want to maximize the number of **rows** available for analysis, even if it means sacrificing a few columns with excessive missing data.\n",
    "\n",
    "In your dataset related to the University of Toronto, consider whether missing values are concentrated in certain courses, professors, or semesters (rows), or if there’s a specific feature like department or credits (columns) that has a lot of missing data. Choose the method that keeps the most valuable and complete information for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d6dc5",
   "metadata": {},
   "source": [
    "### Summary of Exchanges**\n",
    "\n",
    "1. **Missing Data Concepts:**\n",
    "   - **Across Rows**: Missing data in specific rows, where some values are missing but others are present. Example: A student’s grades are missing for certain exams but present for others.\n",
    "   - **Down Columns**: Missing data within specific columns, affecting entire variables. Example: Missing professor names for several courses, but other columns like credits are complete.\n",
    "\n",
    "2. **Efficient Use of `df.dropna()` and `del df['col']`:**\n",
    "   - **`df.dropna()`**:\n",
    "     - **`df.dropna(how=\"any\")`**: Removes rows with any missing value.\n",
    "     - **`df.dropna(how=\"all\")`**: Removes rows where all values are missing.\n",
    "     - **`subset=[\"col1\", \"col2\"]`**: Focuses on specific columns to decide row removal.\n",
    "   - **`del df['col']`**: Deletes columns with excessive missing data, preserving the rest of the dataset.\n",
    "\n",
    "3. **Python Code for Removing Missing Data:**\n",
    "   - **Inspecting Missing Data:**\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     \n",
    "     # Example dataset\n",
    "     data = {\n",
    "         'course_id': [101, 102, 103, 104, 105],\n",
    "         'course_name': ['Math', 'Science', None, 'History', 'Physics'],\n",
    "         'professor': ['Smith', 'Johnson', 'None', None, 'Williams'],\n",
    "         'semester': ['Fall', 'Spring', 'Fall', 'Spring', 'Fall'],\n",
    "         'department': ['Math', 'Science', 'Science', None, None],\n",
    "         'credits': [4, 3, 3, 4, 2]\n",
    "     }\n",
    "     \n",
    "     df = pd.DataFrame(data)\n",
    "     \n",
    "     # Before cleaning\n",
    "     print(\"Before Cleaning:\")\n",
    "     print(df)\n",
    "     print(\"\\nMissing data in each column:\")\n",
    "     print(df.isnull().sum())\n",
    "     ```\n",
    "   - **Cleaning the Data:**\n",
    "     ```python\n",
    "     # Remove the 'department' column\n",
    "     del df['department']\n",
    "     \n",
    "     # Drop rows with missing data in any remaining columns\n",
    "     df_cleaned = df.dropna()\n",
    "     \n",
    "     # After cleaning\n",
    "     print(\"\\nAfter Cleaning:\")\n",
    "     print(df_cleaned)\n",
    "     ```\n",
    "   - **Report of Changes:**\n",
    "     ```python\n",
    "     # Reporting\n",
    "     print(\"\\nReport of Changes:\")\n",
    "     print(f\"Rows before cleaning: {len(data['course_id'])}\")\n",
    "     print(f\"Rows after cleaning: {len(df_cleaned)}\")\n",
    "     \n",
    "     print(f\"\\nColumns before cleaning: {len(data.keys())}\")\n",
    "     print(f\"Columns after cleaning: {len(df_cleaned.columns)}\")\n",
    "     ```\n",
    "\n",
    "   - **Justification**: The `department` column was removed due to excessive missing values. Rows with missing data in any other columns were removed to ensure that the remaining dataset is complete and suitable for analysis.\n",
    "\n",
    "---\n",
    "link: Here's a summary of our exchanges for your homework assignment:\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Exchanges**\n",
    "\n",
    "1. **Missing Data Concepts:**\n",
    "   - **Across Rows**: Missing data in specific rows, where some values are missing but others are present. Example: A student’s grades are missing for certain exams but present for others.\n",
    "   - **Down Columns**: Missing data within specific columns, affecting entire variables. Example: Missing professor names for several courses, but other columns like credits are complete.\n",
    "\n",
    "2. **Efficient Use of `df.dropna()` and `del df['col']`:**\n",
    "   - **`df.dropna()`**:\n",
    "     - **`df.dropna(how=\"any\")`**: Removes rows with any missing value.\n",
    "     - **`df.dropna(how=\"all\")`**: Removes rows where all values are missing.\n",
    "     - **`subset=[\"col1\", \"col2\"]`**: Focuses on specific columns to decide row removal.\n",
    "   - **`del df['col']`**: Deletes columns with excessive missing data, preserving the rest of the dataset.\n",
    "\n",
    "3. **Python Code for Removing Missing Data:**\n",
    "   - **Inspecting Missing Data:**\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     \n",
    "     # Example dataset\n",
    "     data = {\n",
    "         'course_id': [101, 102, 103, 104, 105],\n",
    "         'course_name': ['Math', 'Science', None, 'History', 'Physics'],\n",
    "         'professor': ['Smith', 'Johnson', 'None', None, 'Williams'],\n",
    "         'semester': ['Fall', 'Spring', 'Fall', 'Spring', 'Fall'],\n",
    "         'department': ['Math', 'Science', 'Science', None, None],\n",
    "         'credits': [4, 3, 3, 4, 2]\n",
    "     }\n",
    "     \n",
    "     df = pd.DataFrame(data)\n",
    "     \n",
    "     # Before cleaning\n",
    "     print(\"Before Cleaning:\")\n",
    "     print(df)\n",
    "     print(\"\\nMissing data in each column:\")\n",
    "     print(df.isnull().sum())\n",
    "     ```\n",
    "   - **Cleaning the Data:**\n",
    "     ```python\n",
    "     # Remove the 'department' column\n",
    "     del df['department']\n",
    "     \n",
    "     # Drop rows with missing data in any remaining columns\n",
    "     df_cleaned = df.dropna()\n",
    "     \n",
    "     # After cleaning\n",
    "     print(\"\\nAfter Cleaning:\")\n",
    "     print(df_cleaned)\n",
    "     ```\n",
    "   - **Report of Changes:**\n",
    "     ```python\n",
    "     # Reporting\n",
    "     print(\"\\nReport of Changes:\")\n",
    "     print(f\"Rows before cleaning: {len(data['course_id'])}\")\n",
    "     print(f\"Rows after cleaning: {len(df_cleaned)}\")\n",
    "     \n",
    "     print(f\"\\nColumns before cleaning: {len(data.keys())}\")\n",
    "     print(f\"Columns after cleaning: {len(df_cleaned.columns)}\")\n",
    "     ```\n",
    "\n",
    "   - **Justification**: The `department` column was removed due to excessive missing values. Rows with missing data in any other columns were removed to ensure that the remaining dataset is complete and suitable for analysis.\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e38cf9-4670-800d-bc1b-586b21b67ddc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb443d",
   "metadata": {},
   "source": [
    "Q8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f829fb",
   "metadata": {},
   "source": [
    "Q8-1. \n",
    "GroupBy: When you use df.groupby(\"col1\"), it sorts your data into different groups based on the values in the \"col1\" column. All rows with the same value in \"col1\" end up in the same group.\n",
    "\n",
    "Select a Column: Using [\"col2\"] picks out just the \"col2\" column from each of those groups. So, you’re focusing only on \"col2\" for each group.\n",
    "\n",
    "Describe: When you add .describe(), it gives you key statistics about \"col2\" for each group. This usually includes things like how many values there are, the average, how spread out the values are, and the minimum and maximum values, plus some percentiles (25th, 50th, and 75th)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8-1 example\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Group by 'pclass' (Passenger Class)\n",
    "grouped = titanic.groupby('pclass')\n",
    "\n",
    "# Select the 'age' column\n",
    "age_column = grouped['age']\n",
    "\n",
    "# Compute descriptive statistics for 'age'\n",
    "description = age_column.describe()\n",
    "\n",
    "# Print the result\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500fa68",
   "metadata": {},
   "source": [
    "Q8-2\n",
    "\n",
    "df.describe() gives a general picture of missing data by showing the total number of non-missing values for each column in the  dataset. It doesn't count the missing values (we mentioned it before). \n",
    "But df.groupby(\"col1\")[\"col2\"].describe() performs different by showing the number of non-missing values in col2 for each group defined by col1. This means I get to see how missing data is spread within each specific group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9589dba",
   "metadata": {},
   "source": [
    "Q8-3\n",
    "\n",
    "A. Forget to include import pandas as pd in your code.\n",
    "\n",
    "I think it's better to use chatgpt since it will give you the new version of code which includes the solution to import pandas with import pandas as pd.\n",
    "\n",
    "B. Mistype \"titanic.csv\" as \"titanics.csv\".\n",
    "\n",
    "I tried it on chatgpt and it pointed out these typos really easily.it changed it to ('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv') which removed that typo s.\n",
    "\n",
    "C. Try to use a dataframe before it's been assigned into the variable.\n",
    "\n",
    "Chatgpt fixed the error immediately by saying \"Use the correct DataFrame variable name\". \n",
    "\n",
    "D. Forget one of the parentheses somewhere the code.\n",
    "\n",
    "Chatgpt is better since it wil quickly tell you where you missed the code or evenmore, it will give you the code within the missing parentheses. Overall, chatgpt is better for quick syntax corrections.\n",
    "\n",
    "E. Mistype one of the names of the chained functions with the code.\n",
    "\n",
    "Since this is the detailed problems with functions or understanding how to use them correctly, google is better. \n",
    "\n",
    "F. Use a column name that's not in your data for the groupby and column selection.\n",
    "\n",
    "Chatgpt is better since it will directly point out which column name you wrote it wrong within a few seconds. It will help you to use the name within my data or remove it to fix the error. \n",
    "\n",
    "G. Forget to put the column name as a string in quotes for the groupby and column selection.\n",
    "\n",
    "Google was faster in this case. It pointed out the missing quotes and suggested the correct format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa549d",
   "metadata": {},
   "source": [
    "### Summary of Interactions\n",
    "\n",
    "1. **Data Manipulation with Pandas**:\n",
    "   - **Objective**: Understand how `df.groupby(\"col1\")[\"col2\"].describe()` works and compare it with `df.describe()`.\n",
    "   - **Explanation**:\n",
    "     - `df.describe()`: Provides a summary of numeric columns, including statistics such as count, mean, standard deviation, and percentiles. The `count` value reflects the number of non-null entries in each column.\n",
    "     - `df.groupby(\"col1\")[\"col2\"].describe()`: Groups the DataFrame by `col1` and then provides descriptive statistics for `col2` within each group. The `count` here reflects the number of non-null entries for `col2` within each group defined by `col1`.\n",
    "\n",
    "2. **Error Troubleshooting**:\n",
    "   - **Code Example**:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "\n",
    "     # Load the Titanic dataset\n",
    "     url = 'https://web.stanford.edu/class/archive/cs/cs109/cs/cs109.1166/stuff/titanics.csv'\n",
    "     df = pd.read_csv(url)\n",
    "\n",
    "     # Group by 'Pclass' and describe the 'Age' column\n",
    "     grouped_age_description = df.groupby(\"Pclass\")[\"Age\"].describe()\n",
    "\n",
    "     print(grouped_age_description)\n",
    "     ```\n",
    "   - **Errors Identified**:\n",
    "     - **Typo in Variable Name**: Ensure consistent use of variable names (`df` vs. `Df`).\n",
    "     - **Typo in Method Name**: Use `groupby` instead of `grou`.\n",
    "     - **Mismatch in Column Name**: Ensure that the column used in `describe()` matches the intended column (`Age` vs. `Sex`).\n",
    "\n",
    "3. **Code Fixes**:\n",
    "   - Corrected the variable name consistency.\n",
    "   - Fixed the typo from `df.grou(\"Pclass\")` to `df.groupby(\"Pclass\")`.\n",
    "   - Ensured that the correct column (`Age`) is used for describing the grouped data.\n",
    "\n",
    "### Final Corrected Code\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs/cs109.1166/stuff/titanics.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check column names to ensure 'Pclass' and 'Age' exist\n",
    "print(\"Column names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Group by 'Pclass' and describe the 'Age' column\n",
    "if 'Pclass' in df.columns and 'Age' in df.columns:\n",
    "    grouped_age_description = df.groupby(\"Pclass\")[\"Age\"].describe()\n",
    "    print(\"\\nGrouped Age Description:\")\n",
    "    print(grouped_age_description)\n",
    "else:\n",
    "    print(\"Columns 'Pclass' and/or 'Age' are not in the DataFrame.\")\n",
    "```\n",
    "\n",
    "---\n",
    "link: https://chatgpt.com/c/66e390e7-c70c-800d-90db-1bb6b0584600"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
